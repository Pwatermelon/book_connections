"""
–û—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥—É–ª—å –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø—Ä–æ–≥—Ä–∞–º–º—ã –∞–Ω–∞–ª–∏–∑–∞ —Å–≤—è–∑–µ–π –≤ –∫–Ω–∏–≥–µ.
"""
import sys
import os
from pathlib import Path
from entity_extractor import EntityExtractor
from relation_extractor import RelationExtractor
from ontology_builder import OntologyBuilder
from graph_visualizer import GraphVisualizer


def load_text_from_file(file_path: str) -> str:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫–∏.
    
    Args:
        file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å —Ç–µ–∫—Å—Ç–æ–º
        
    Returns:
        –¢–µ–∫—Å—Ç –∫–Ω–∏–≥–∏
    """
    try:
        # –°–ø–∏—Å–æ–∫ –∫–æ–¥–∏—Ä–æ–≤–æ–∫ –¥–ª—è –ø–æ–ø—ã—Ç–∫–∏ —á—Ç–µ–Ω–∏—è
        encodings = ['utf-8', 'windows-1251', 'cp866', 'iso-8859-5', 'utf-8-sig']
        
        # –ü—Ä–æ–±—É–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–æ–¥–∏—Ä–æ–≤–∫—É –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
        try:
            import chardet
            with open(file_path, 'rb') as f:
                raw_data = f.read(10000)  # –ß–∏—Ç–∞–µ–º –ø–µ—Ä–≤—ã–µ 10KB –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
                detected = chardet.detect(raw_data)
                if detected and detected['encoding']:
                    encodings.insert(0, detected['encoding'])
        except ImportError:
            pass  # chardet –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–∏—Å–æ–∫ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        except Exception:
            pass
        
        # –ü—Ä–æ–±—É–µ–º –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª —Å —Ä–∞–∑–Ω—ã–º–∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∞–º–∏
        for encoding in encodings:
            try:
                with open(file_path, 'r', encoding=encoding) as f:
                    text = f.read()
                    return text
            except (UnicodeDecodeError, LookupError):
                continue
        
        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ, –ø—Ä–æ–±—É–µ–º —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
        try:
            with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
                return f.read()
        except Exception as e:
            raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª. –í–æ–∑–º–æ–∂–Ω–∞ –ø—Ä–æ–±–ª–µ–º–∞ —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π: {e}")
            
    except FileNotFoundError:
        print(f"–û—à–∏–±–∫–∞: –§–∞–π–ª {file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        sys.exit(1)
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
        sys.exit(1)


def save_ontology(ontology: dict, output_file: str):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ–Ω—Ç–æ–ª–æ–≥–∏—é –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª."""
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("–û–ù–¢–û–õ–û–ì–ò–Ø –°–í–Ø–ó–ï–ô\n")
        f.write("=" * 80 + "\n\n")
        
        # –°—É—â–Ω–æ—Å—Ç–∏
        f.write(f"–°–£–©–ù–û–°–¢–ò (–≤—Å–µ–≥–æ: {len(ontology['entities'])}):\n")
        f.write("-" * 80 + "\n")
        for name, data in ontology['entities'].items():
            f.write(f"  {name} [{data['type']}]\n")
            f.write(f"    –£–ø–æ–º–∏–Ω–∞–Ω–∏–π: {data['attributes'].get('mentions', 0)}\n")
            f.write(f"    –í—Å–µ–≥–æ —Å–≤—è–∑–µ–π: {data['attributes'].get('total_relations', 0)}\n")
            f.write("\n")
        
        # –°–≤—è–∑–∏
        f.write(f"\n–°–í–Ø–ó–ò (–≤—Å–µ–≥–æ: {len(ontology['relations'])}):\n")
        f.write("-" * 80 + "\n")
        for relation in ontology['relations']:
            f.write(f"  {relation['source']} --[{relation['type']}]--> {relation['target']}\n")
            if relation.get('context'):
                f.write(f"    –ö–æ–Ω—Ç–µ–∫—Å—Ç: {relation['context'][:100]}...\n")
            f.write("\n")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–æ–≥—Ä–∞–º–º—ã."""
    print("=" * 80)
    print("–ê–ù–ê–õ–ò–ó –°–í–Ø–ó–ï–ô –ò–ú–Å–ù –°–û–ë–°–¢–í–ï–ù–ù–´–• –í –ö–ù–ò–ì–ï")
    print("=" * 80)
    print()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    if len(sys.argv) < 2:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python main.py <–ø—É—Ç—å_–∫_–∫–Ω–∏–≥–µ.txt> [–ø—É—Ç—å_–∫_–≤—ã—Ö–æ–¥–Ω–æ–º—É_–≥—Ä–∞—Ñ—É.html]")
        print()
        print("–ü—Ä–∏–º–µ—Ä:")
        print("  python main.py book.txt graph.html")
        sys.exit(1)
    
    input_file = sys.argv[1]
    output_graph = sys.argv[2] if len(sys.argv) > 2 else 'graph.html'
    output_ontology = 'ontology.txt'
    
    print(f"üìñ –ó–∞–≥—Ä—É–∑–∫–∞ –∫–Ω–∏–≥–∏ –∏–∑ —Ñ–∞–π–ª–∞: {input_file}")
    text = load_text_from_file(input_file)
    print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å–∏–º–≤–æ–ª–æ–≤: {len(text):,}")
    print()
    
    # –®–∞–≥ 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–µ–π
    print("üîç –®–∞–≥ 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–º–µ–Ω —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö...")
    entity_extractor = EntityExtractor()
    entities = entity_extractor.extract_entities(text)
    
    total_entities = sum(len(ents) for ents in entities.values())
    print(f"   –ù–∞–π–¥–µ–Ω–æ —Å—É—â–Ω–æ—Å—Ç–µ–π:")
    print(f"     - –ü–µ—Ä—Å–æ–Ω—ã: {len(entities.get('PERSON', []))}")
    print(f"     - –õ–æ–∫–∞—Ü–∏–∏: {len(entities.get('LOC', []))}")
    print(f"     - –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏: {len(entities.get('ORG', []))}")
    print(f"     - –í—Å–µ–≥–æ: {total_entities}")
    print()
    
    # –®–∞–≥ 2: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–≤—è–∑–µ–π
    print("üîó –®–∞–≥ 2: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–≤—è–∑–µ–π –º–µ–∂–¥—É —Å—É—â–Ω–æ—Å—Ç—è–º–∏...")
    relation_extractor = RelationExtractor()
    relations = relation_extractor.extract_relations(text, entities)
    print(f"   –ù–∞–π–¥–µ–Ω–æ —Å–≤—è–∑–µ–π: {len(relations)}")
    
    if relations:
        relation_types = {}
        for rel in relations:
            rel_type = rel['type']
            relation_types[rel_type] = relation_types.get(rel_type, 0) + 1
        print(f"   –¢–∏–ø—ã —Å–≤—è–∑–µ–π:")
        for rel_type, count in relation_types.items():
            print(f"     - {rel_type}: {count}")
    print()
    
    # –®–∞–≥ 3: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –æ–Ω—Ç–æ–ª–æ–≥–∏–∏
    print("üìä –®–∞–≥ 3: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –æ–Ω—Ç–æ–ª–æ–≥–∏–∏...")
    ontology_builder = OntologyBuilder()
    ontology = ontology_builder.build_ontology(entities, relations)
    statistics = ontology_builder.get_statistics()
    print(f"   –û–Ω—Ç–æ–ª–æ–≥–∏—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∞!")
    print(f"   –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"     - –°—É—â–Ω–æ—Å—Ç–µ–π: {statistics['total_entities']}")
    print(f"     - –°–≤—è–∑–µ–π: {statistics['total_relations']}")
    print()
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–Ω—Ç–æ–ª–æ–≥–∏–∏
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–Ω—Ç–æ–ª–æ–≥–∏–∏ –≤ {output_ontology}...")
    save_ontology(ontology, output_ontology)
    print()
    
    # –®–∞–≥ 4: –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–∞—Ñ–∞
    print("üé® –®–∞–≥ 4: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞...")
    graph_visualizer = GraphVisualizer()
    graph = graph_visualizer.build_graph(ontology)
    graph_info = graph_visualizer.get_graph_info()
    
    print(f"   –ì—Ä–∞—Ñ –ø–æ—Å—Ç—Ä–æ–µ–Ω!")
    print(f"     - –£–∑–ª–æ–≤: {graph_info['nodes']}")
    print(f"     - –†—ë–±–µ—Ä: {graph_info['edges']}")
    print(f"     - –ü–ª–æ—Ç–Ω–æ—Å—Ç—å: {graph_info['density']:.4f}")
    print(f"     - –°–≤—è–∑–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: {graph_info['components']}")
    print()
    
    print(f"üé® –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏...")
    output_path = graph_visualizer.visualize_interactive(output_file=output_graph)
    print()
    
    print("=" * 80)
    print("‚úÖ –ì–û–¢–û–í–û!")
    print("=" * 80)
    print(f"üìä –ì—Ä–∞—Ñ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
    print(f"üìÑ –û–Ω—Ç–æ–ª–æ–≥–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {output_ontology}")
    print()
    print("–û—Ç–∫—Ä–æ–π—Ç–µ HTML —Ñ–∞–π–ª –≤ –±—Ä–∞—É–∑–µ—Ä–µ –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –≥—Ä–∞—Ñ–∞!")


if __name__ == '__main__':
    main()

